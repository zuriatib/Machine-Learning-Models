{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pixels', 'overfeat', 'labels', 'names', 'allow_pickle'])\n"
     ]
    }
   ],
   "source": [
    "with np.load('cifar4-train.npz',allow_pickle=False) as npz_file:\n",
    "    data = dict(npz_file.items())\n",
    "    print (data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X/y arrays\n",
    "X = data['overfeat']\n",
    "y = data['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy (\"most-frequent\"): 0.227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Evaluate baseline\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "accuracy = dummy.score(X_test, y_test)\n",
    "print('Baseline accuracy (\"most-frequent\"): {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Chose LinearSVC as it scales better to a large number of samples.\n",
    "\n",
    "2) Chose SVC as it's used for non linear classification, which is appropriate for our classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier with linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=150, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('linearsvc', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'linearsvc__C': [0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=150)\n",
    "pipe = Pipeline([('pca',pca),('linearsvc',LinearSVC())])\n",
    "\n",
    "#create grid search with cross-validation object\n",
    "grid_cv = GridSearchCV(pipe,{'linearsvc__C':[0.001,0.01,0.1,1,10]},cv=5)\n",
    "\n",
    "#fit the estimator\n",
    "grid_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_linearsvc__C', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score', 'split4_train_score', 'mean_train_score', 'std_train_score'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_items([('C',grid_cv.cv_results_['param_linearsvc__C']),\n",
    "                             ('mean test',grid_cv.cv_results_['mean_test_score']),\n",
    "                             ('std test',grid_cv.cv_results_['std_test_score']),\n",
    "                              ('mean train',grid_cv.cv_results_['mean_train_score']),\n",
    "                              ('std train',grid_cv.cv_results_['std_train_score']),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>mean test</th>\n",
       "      <th>std test</th>\n",
       "      <th>mean train</th>\n",
       "      <th>std train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.83350</td>\n",
       "      <td>0.008461</td>\n",
       "      <td>0.868439</td>\n",
       "      <td>0.003336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.83250</td>\n",
       "      <td>0.012877</td>\n",
       "      <td>0.875752</td>\n",
       "      <td>0.004441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.82775</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.876939</td>\n",
       "      <td>0.005193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.78900</td>\n",
       "      <td>0.012334</td>\n",
       "      <td>0.821562</td>\n",
       "      <td>0.009081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.76050</td>\n",
       "      <td>0.029278</td>\n",
       "      <td>0.793819</td>\n",
       "      <td>0.019945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C  mean test  std test  mean train  std train\n",
       "0  0.001    0.83350  0.008461    0.868439   0.003336\n",
       "1   0.01    0.83250  0.012877    0.875752   0.004441\n",
       "2    0.1    0.82775  0.010599    0.876939   0.005193\n",
       "3      1    0.78900  0.012334    0.821562   0.009081\n",
       "4     10    0.76050  0.029278    0.793819   0.019945"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mean test'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM - top accuracy across folds: 0.834 (std: 0.008) with C: 0.001\n"
     ]
    }
   ],
   "source": [
    "print ('Linear SVM - top accuracy across folds: {:.3f} (std: {:.3f}) with C: {}'.format(df.loc[0,'mean test'],\n",
    "                                                                                        df.loc[0,'std test'],\n",
    "                                                                                       df.loc[0,'C']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=150, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('svc_rbf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'svc_rbf__C': [0.1, 1, 10, 20], 'svc_rbf__gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_rbf = SVC(kernel='rbf',random_state=0)\n",
    "pipe = Pipeline([('pca',pca),('svc_rbf',svc_rbf)])\n",
    "\n",
    "grid_cv_rbf = GridSearchCV(pipe, {'svc_rbf__C':[0.1,1,10,20],'svc_rbf__gamma':[0.001,0.01,0.1,1]},cv=5)\n",
    "grid_cv_rbf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_svc_rbf__C', 'param_svc_rbf__gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score', 'split4_train_score', 'mean_train_score', 'std_train_score'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_rbf.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rbf = pd.DataFrame.from_items([('C',grid_cv_rbf.cv_results_['param_svc_rbf__C']),\n",
    "                                  ('gamma',grid_cv_rbf.cv_results_['param_svc_rbf__gamma']),\n",
    "                             ('mean test',grid_cv_rbf.cv_results_['mean_test_score']),\n",
    "                             ('std test',grid_cv_rbf.cv_results_['std_test_score']),\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>mean test</th>\n",
       "      <th>std test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.80875</td>\n",
       "      <td>0.010669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.80750</td>\n",
       "      <td>0.011109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.80300</td>\n",
       "      <td>0.007927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.62750</td>\n",
       "      <td>0.014225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25625</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C  gamma  mean test  std test\n",
       "12   20  0.001    0.80875  0.010669\n",
       "8    10  0.001    0.80750  0.011109\n",
       "4     1  0.001    0.80300  0.007927\n",
       "0   0.1  0.001    0.62750  0.014225\n",
       "5     1   0.01    0.25625  0.000786"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rbf.sort_values('mean test',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rbf['mean test'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVM - top accuracy across folds: 0.807 (std: 0.011) with C: 10 and gamma 0.001\n"
     ]
    }
   ],
   "source": [
    "print ('RBF SVM - top accuracy across folds: {:.3f} (std: {:.3f}) with C: {} and gamma {}'.format(df_rbf.loc[8,'mean test'],\n",
    "                                                                                        df_rbf.loc[8,'std test'],\n",
    "                                                                                       df_rbf.loc[8,'C'],\n",
    "                                                                                                 df_rbf.loc[8,'gamma']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned estimators on 1,000 test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM accuracy (test set): 0.815\n",
      "RBF SVM accuracy (test set): 0.809\n"
     ]
    }
   ],
   "source": [
    "accuracy = grid_cv.score(X_test,y_test)\n",
    "accuracy_rbf = grid_cv_rbf.score(X_test,y_test)\n",
    "print ('Linear SVM accuracy (test set): {:.3f}'.format(accuracy))\n",
    "print ('RBF SVM accuracy (test set): {:.3f}'.format(accuracy_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection - SVM RBF Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at all the results, SVM Linear, SVM RBF, Logistics and FC NN seems to have the best test accuracy. \n",
    "\n",
    "    1) I eliminated SVM Linear as I consider image classification as not linear. \n",
    "    2) I equally elimiated Logistics because afer running the predict_proba() and printing out the images, it did not reflect correctly what was predicted against the real image.\n",
    "    3) I finally chose SVM RBF based on Occam's razor, simpler one is usually better.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pixels', 'overfeat', 'allow_pickle'])\n"
     ]
    }
   ],
   "source": [
    "#load test set\n",
    "with np.load('cifar4-test.npz',allow_pickle=False) as npz_file:\n",
    "    test_set = dict(npz_file.items())\n",
    "    print (test_set.keys())\n",
    "\n",
    "X_test_set = test_set['overfeat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid_cv_rbf.predict(X_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to an .npy file\n",
    "np.save('test-predictions.npy',results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, 3, 2, 3, 3, 3, 0, 3, 3, 0, 1, 1, 0, 2, 1, 1, 2, 1, 1, 0,\n",
       "       1, 2, 3, 1, 2, 0, 2, 1, 0, 0, 2, 1, 3, 0, 1, 1, 1, 3, 2, 3, 0, 2,\n",
       "       2, 2, 1, 1, 0, 2, 3, 1, 0, 1, 2, 0, 0, 2, 0, 1, 0, 0, 0, 0, 2, 1,\n",
       "       2, 2, 0, 1, 2, 3, 3, 2, 3, 3, 3, 3, 3, 1, 2, 0, 2, 3, 3, 0, 2, 3,\n",
       "       3, 2, 2, 1, 1, 0, 1, 2, 1, 1, 3, 1, 3, 2, 0, 3, 2, 2, 1, 2, 1, 3,\n",
       "       0, 1, 1, 0, 3, 1, 2, 1, 1, 2, 0, 1, 2, 1, 2, 2, 3, 1, 1, 1, 0, 1,\n",
       "       0, 3, 3, 2, 2, 1, 1, 1, 0, 3, 3, 2, 1, 2, 3, 2, 1, 1, 1, 2, 2, 2,\n",
       "       3, 1, 3, 0, 3, 2, 0, 2, 0, 1, 2, 1, 0, 3, 3, 3, 0, 3, 0, 3, 0, 2,\n",
       "       1, 2, 2, 0, 0, 2, 1, 0, 1, 2, 3, 1, 1, 0, 3, 0, 0, 0, 2, 3, 1, 2,\n",
       "       3, 2, 3, 0, 3, 0, 1, 2, 1, 1, 2, 1, 0, 2, 1, 0, 3, 1, 0, 0, 0, 0,\n",
       "       1, 3, 3, 2, 1, 0, 3, 3, 0, 1, 2, 1, 2, 3, 1, 3, 2, 2, 2, 2, 1, 3,\n",
       "       1, 3, 3, 2, 1, 3, 2, 2, 2, 1, 2, 2, 3, 2, 2, 1, 1, 3, 3, 1, 2, 2,\n",
       "       1, 1, 1, 3, 3, 0, 1, 3, 0, 2, 0, 2, 1, 2, 1, 1, 0, 2, 0, 3, 3, 2,\n",
       "       2, 3, 3, 1, 1, 0, 2, 1, 2, 2, 3, 2, 0, 3, 1, 0, 3, 2, 3, 3, 1, 1,\n",
       "       1, 0, 2, 0, 0, 0, 2, 0, 2, 1, 2, 2, 0, 1, 3, 3, 3, 3, 3, 0, 1, 1,\n",
       "       0, 1, 3, 2, 3, 0, 1, 3, 1, 2, 3, 0, 1, 0, 0, 3, 1, 0, 2, 2, 0, 2,\n",
       "       3, 3, 3, 2, 3, 1, 1, 0, 1, 3, 3, 0, 0, 0, 3, 3, 0, 1, 2, 2, 2, 3,\n",
       "       0, 2, 3, 1, 3, 2, 1, 0, 2, 0, 2, 2, 1, 2, 2, 2, 0, 1, 2, 2, 3, 1,\n",
       "       1, 1, 0, 3, 0, 2, 3, 3, 3, 3, 3, 2, 3, 3, 1, 1, 2, 0, 0, 2, 3, 3,\n",
       "       3, 2, 0, 2, 3, 1, 1, 1, 1, 1, 1, 2, 3, 3, 0, 1, 0, 0, 2, 2, 2, 3,\n",
       "       3, 3, 2, 3, 0, 3, 3, 1, 1, 3, 1, 3, 1, 0, 2, 1, 2, 0, 1, 0, 2, 0,\n",
       "       0, 1, 1, 2, 1, 3, 1, 2, 3, 3, 0, 0, 3, 1, 0, 0, 3, 3, 2, 1, 1, 1,\n",
       "       1, 1, 1, 3, 1, 1, 2, 1, 0, 2, 1, 0, 2, 0, 1, 3, 0, 0, 3, 0, 3, 3,\n",
       "       3, 2, 0, 1, 1, 3, 0, 3, 2, 3, 0, 1, 0, 0, 2, 1, 1, 3, 3, 1, 3, 3,\n",
       "       2, 0, 3, 0, 3, 3, 2, 2, 1, 3, 1, 1, 1, 0, 3, 2, 1, 2, 1, 2, 3, 3,\n",
       "       1, 2, 3, 3, 3, 1, 0, 0, 3, 1, 3, 2, 3, 0, 0, 1, 2, 1, 1, 1, 2, 2,\n",
       "       1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 3, 3, 3, 0, 2, 3, 1, 3, 1, 3, 2, 3,\n",
       "       3, 2, 0, 1, 0, 0, 1, 2, 0, 1, 1, 0, 1, 3, 0, 0, 1, 2, 2, 1, 0, 0,\n",
       "       2, 3, 3, 1, 2, 1, 1, 3, 2, 3, 1, 0, 2, 3, 3, 1, 2, 2, 0, 0, 1, 0,\n",
       "       0, 1, 3, 1, 2, 3, 2, 0, 1, 3, 0, 2, 3, 1, 1, 1, 1, 3, 1, 3, 0, 1,\n",
       "       1, 3, 2, 3, 3, 1, 0, 1, 1, 1, 2, 3, 1, 1, 1, 2, 0, 0, 1, 0, 0, 3,\n",
       "       1, 0, 0, 1, 0, 3, 0, 0, 1, 0, 3, 1, 1, 1, 2, 2, 0, 1, 0, 3, 2, 0,\n",
       "       1, 0, 1, 3, 3, 1, 1, 0, 1, 0, 3, 1, 1, 0, 3, 0, 0, 1, 1, 1, 0, 0,\n",
       "       2, 0, 1, 1, 3, 1, 2, 1, 1, 3, 3, 1, 2, 3, 2, 1, 1, 1, 2, 3, 0, 2,\n",
       "       0, 1, 1, 0, 2, 0, 0, 0, 1, 0, 2, 1, 3, 1, 0, 0, 0, 1, 0, 2, 0, 2,\n",
       "       2, 3, 0, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 0, 0, 3, 1, 1, 0, 0, 0, 2,\n",
       "       1, 2, 3, 0, 0, 3, 0, 1, 1, 0, 1, 3, 3, 3, 3, 1, 2, 3, 2, 2, 1, 3,\n",
       "       0, 0, 3, 2, 1, 0, 2, 2, 0, 2, 2, 3, 1, 2, 3, 1, 0, 1, 2, 0, 1, 1,\n",
       "       2, 2, 1, 1, 3, 2, 1, 1, 3, 0, 1, 0, 2, 1, 2, 0, 3, 3, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 2, 3, 0, 1, 2, 0, 0, 0, 3, 2, 2, 1, 1, 0, 1, 0, 3,\n",
       "       2, 0, 2, 0, 1, 3, 0, 2, 0, 1, 0, 1, 2, 1, 3, 1, 1, 3, 2, 3, 2, 1,\n",
       "       1, 3, 3, 0, 0, 0, 1, 0, 3, 0, 1, 1, 2, 2, 1, 1, 2, 2, 0, 1, 3, 2,\n",
       "       2, 3, 3, 3, 2, 3, 1, 2, 1, 0, 3, 2, 2, 3, 0, 2, 3, 1, 1, 3, 1, 1,\n",
       "       0, 3, 3, 1, 2, 1, 3, 0, 2, 1, 3, 2, 3, 1, 0, 1, 3, 3, 3, 2, 1, 1,\n",
       "       3, 2, 3, 2, 3, 1, 0, 2, 2, 2, 0, 1, 3, 0, 3, 1, 0, 3, 2, 2, 2, 0,\n",
       "       0, 1, 3, 1, 0, 1, 1, 1, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
